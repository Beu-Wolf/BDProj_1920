\documentclass[12pt]{report}
\usepackage[textwidth=17cm, margin=2cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{listings}

\begin{document}

    \begin{titlepage}
        \begin{center}

            \vspace*{\fill}
            \Huge
            \textbf{Projeto de Bases de Dados - Parte 3}

            \vspace*{\fill}

            \Large
            \textbf{Grupo 27} \\
            89427 - Daniel Seara - 33,3\% - 6 horas \\
            89399 - Afonso Gonçalves - 33,3\% - 6 horas \\
            89496 - Marcelo Santos - 33,3\% - 6 horas \\

            \bigskip
            \textbf{Turno:} 4ª Feira 9h30 - Lab 8\\ \textbf{Professor:} Duarte Galvão

        \end{center}
    \end{titlepage}

    \Large
    \textbf{Restrições de Integridade}\\
    \normalsize
    \par Foram usados triggers para implementar as Restrições de Integridade, apresentados de seguida:
    \footnotesize
    \begin{verbatim}
    -- RI-1
    create or replace function
    check_overlap_proc() returns trigger as $$
        declare
            zona1   box;
        begin
            select zona into zona1
            from anomalia where id=new.id;

            if zona1 && new.zona2 then
                raise exception
                'As zonas da anomalia % não se podem intersetar.', new.id;
            end if;
            return new;
        end;
    $$ language plpgsql;

    create trigger check_overlap
    after insert on anomalia_traducao
    for each row execute procedure check_overlap_proc();

    -- RI-4
    create or replace function
    check_completeness_proc() returns trigger as $$
        declare
            inRegular   boolean;
            inQualified boolean;
        begin
            select exists(
                select 1
                from utilizador_regular
                where email = new.email
            ) into inRegular;

            select exists(
                select 1
                from utilizador_qualificado
                where email = new.email
            ) into inQualified;

            if inRegular and inQualified then
                raise exception
                'Utilizador % não pode estar em utilizador_regular e\
                utilizador qualificado simultaneamente', new.email;

            elseif (not inRegular and not inQualified) then
                raise exception
                'Utilizador % tem de estar em utilizador_regular\
                ou utilizador_qualificado', new.email;
            end if;
            return new;
        end;
    $$ language plpgsql;

    create constraint trigger check_completeness
    after insert on utilizador
    deferrable initially deferred
    for each row execute procedure check_completeness_proc();

    -- RI-5
    create or replace function
    check_user_qualificado_proc() returns trigger as $$
        declare
            inRegular boolean;
        begin
            select exists(
                select 1
                from utilizador_regular
                where email = new.emai
            ) into inRegular;

            if inRegular then
                raise exception
                'Utilizador % já está em utilizador_regular', new.email;
            end if;
            return new;
        end;
    $$ language plpgsql;

    create trigger check_user_qualificado
    after insert on utilizador_qualificado
    for each row execute procedure check_user_qualificado_proc();

    --RI-6
    create or replace function
    check_user_regular_proc() returns trigger as $$
        declare
            inQualified boolean;
        begin
            select exists(
                select 1
                from utilizador_qualificado
                where email = new.email
            ) into inQualified;

            if inQualified then
                raise exception
                'Utilizador % já está em utilizador_qualificado', new.email;
            end if;
            return new;
        end;
    $$ language plpgsql;

    create trigger check_user_regular
    after insert on utilizador_regular
    for each row execute procedure check_user_regular_proc();
    \end{verbatim}
    \normalsize

    \newpage
    \Large
    \textbf{Índices}
    \normalsize \\
    \par \textbf{1.1.} Um índice na tabela proposta\_de\_correcao com o atributo data\_hora como chave de procura é um índice \textit{unclustered}: No pior dos casos, seria necessário percorrer todas as páginas do disco pela qual a tabela se distribui para se encontrar um resultado.

    \par Tendo em conta que esta query devolve mais de 10\% do total de registos da tabela e que o custo associado à indexação (percorrer a $B^+$ Tree, juntamente com o custo associado a carregar de disco todas as páginas de memória necessárias para encontrar o resultado pretendido) pode muito provavelmente ultrapassar o custo de apenas percorrer a tabela toda, não compensa criar um índice para esta pesquisa.

    \par Esta ideia é reforçada pela bibliografia da cadeira:
    \begin{quotation}
        "As a rule of thumb, it is probably cheaper to simply scan the entire table (instead of using an unclustered index) if over 5\% of the tuples are to be retrieved."
    \end{quotation}

    \par \textbf{1.2.} Seguindo o raciocínio usado na questão anterior e tendo em conta que, neste caso, o query devolve menos de 0.001\% do total de registos da tabela, é justificável a utilização de índices.

    \par Como o filtro de pesquisa é um intervalo de valores, decidiu-se implementar um índice com $B^+$ Tree, uma vez que é o mais adequado para este tipo de procura: Ao contrário dos Hash Indices, a $B^+$ Tree guarda as referências para os registos, ordenados por chave. Deste modo é possível filtrar um intervalo destes mesmos índices, encontrando o índice com o valor mínimo para o intervalo e explorando o conjunto ordenado dos índices sucessores, enquanto estes ainda estiverem dentro do intervalo pretendido.
    \par O índice foi aplicado sobre o atributo \textit{{data\_hora}} da tabela \textit{proposta\_de\_correcao}:\\
    \footnotesize \begin{verbatim}
        create index idx_data_hora on proposta_de_correcao using btree (data_hora);
    \end{verbatim}\normalsize

    \par \textbf{2.} Nesta query está a ser procurado um registo pela sua \textit{primary key}. Como o \textit{pgsql} cria automaticamente um índice para as chaves primárias de cada tabela, não será necessário criar um novo índice.\\

    \par \textbf{3.1.} Pelas mesmas razões apresentadas em 1.1, este caso não é o melhor para se usar índices, acabando a sua implementação por ser mais dispendiosa do que uma procura simples.\\

    \par \textbf{3.2.} Usando o mesmo raciocínio usado em 1.1 e em 1.2, decidiu-se usar uma $B^+$ Tree na tabela \textit{correcao}, usando como chave \textit{anomalia\_id}:\\
    \footnotesize \begin{verbatim}
        create index idx_anomalia_id on correcao using btree (anomalia_id);
    \end{verbatim}\normalsize


    \par \textbf{4.} Chegou-se à conclusão de que, para este caso, o filtro \textit{LIKE} atua como um \textit{<BETWEEN x AND y>}, sendo \textit{x} o padrão dado e \textit{y} o seu sucessor lexicográfico com o mesmo número de caracteres. Por exemplo, se o padrão for \textit{ABC\%}, o filtro selecionará todas as \textit{strings s} tal que \textit{ABC} $<= s <$ \textit{ABD}, lexicograficamente.

    \par Se a percentagem de registos devolvidos por esta \textit{query} for superior a 5\%, dada a análise feita nas respostas anteriores, não se justifica utilizar indexação. Caso contrário, utilizar-se-ia uma $B^+$ Tree (dado que \textit{Hash Indices} não suportam índices múltiplos) na tabela \textit{anomalia} com a chave múltipla \textit{(ts, language)}.
    \par Para optimizar a \textit{query}, decidiu-se reduzir ao máximo o espaço de possíveis resultados, selecionando logo de início os registos que sejam anomalia de redação. Para o índice ficar coerente com a \textit{query}, é necessário mudar a ordem pela qual as colunas aparecem na mesma:
    \footnotesize
    \begin{verbatim}
select id, lingua, descricao
from anomalia
where tem_anomalia_redacao = True
    and ts between <ts_1> and <ts_2>
    and language like '<SOME_PATTERN>%';
    \end{verbatim}
    \normalsize


    \footnotesize \begin{verbatim}
create index idx_ts_language on anomalia
    using btree (tem_anomalia_redacao, ts, language);
    \end{verbatim}\normalsize

    \Large
    \textbf{Modelo Multidimensional}\\
    \normalsize
    \par Para criar um modelo Multidimensional, usou-se um esquema em estrela com as dimensões Utilizador, Tempo, Local e Língua. De seguida apresenta-se o código usado para o criar:

    \footnotesize \begin{verbatim}
drop table d_utilizador cascade;
drop table d_tempo cascade;
drop table d_local cascade;
drop table d_lingua cascade;
drop table f_anomalia cascade;

create table d_utilizador (
    id_utilizador serial,
    email         varchar(255) not null,
    tipo          varchar(255) not null,
    constraint pk_d_utilizador primary key(id_utilizador)
);

insert into d_utilizador (email, tipo)
select email, 'qualificado' as tipo
from utilizador_qualificado
union select email, 'regular' as tipo
from utilizador_regular;

create table d_tempo (
    id_tempo        serial,
    dia             integer not null,
    dia_da_semana   integer not null,
    semana          integer not null,
    mes             integer not null,
    trimestre       integer not null,
    ano             integer not null,
    constraint pk_d_tempo primary key(id_tempo)
);

insert into d_tempo(dia, dia_da_semana, semana, mes, trimestre, ano)
select  extract(day from ts),
        extract(isodow from ts),
        extract(week  from ts),
        extract(month from ts),
        extract(quarter from ts),
        extract(year from ts)
from anomalia union select extract(day from data_hora),
       extract(isodow from data_hora),
       extract(week  from data_hora),
       extract(month from data_hora),
       extract(quarter from data_hora),
       extract(year from data_hora)
from proposta_de_correcao;

create table d_local (
    id_local    serial,
    latitude    numeric(8, 6) not null,
    longitude   numeric(9, 6) not null,
    nome        varchar(255)  not null,
    constraint pk_d_local primary key(id_local)
);

insert into d_local (latitude, longitude, nome)
select latitude, longitude, nome from local_publico;

create table d_lingua (
    id_lingua   serial,
    lingua      varchar(255) not null,
    constraint pk_d_lingua primary key(id_lingua)
);

insert into d_lingua (lingua)
select distinct lingua from anomalia
union select distinct lingua2 from anomalia_traducao;

create table f_anomalia (
    id_utilizador   integer,
    id_tempo        integer,
    id_local        integer,
    id_lingua       integer,
    tipo_anomalia   varchar(255) not null,
    com_proposta    boolean not null,
    constraint fk_utilizador foreign key(id_utilizador)
        references d_utilizador(id_utilizador) on delete cascade,
    constraint fk_tempo foreign key(id_tempo)
        references d_tempo(id_tempo) on delete cascade,
    constraint fk_local foreign key(id_local)
        references d_local(id_local) on delete cascade,
    constraint fk_lingua foreign key(id_lingua)
        references d_lingua(id_lingua) on delete cascade,
    constraint pk_f_anomalia primary key(id_utilizador, id_tempo, id_local, id_lingua)
);

create or replace function get_tipo_anomalia(id integer) returns varchar(255) as $$
begin
    if id in (select A.id from anomalia_traducao A) then
        return 'traducao';
    else
        return 'redacao';
    end if;
end $$ language plpgsql;

create or replace function anomalia_tem_proposta(id integer) returns boolean as $$
begin
    if id in (select anomalia_id from correcao) then
        return true;
    else
        return false;
    end if;
end
$$ language plpgsql;

insert into f_anomalia (id_utilizador, id_tempo, id_local, id_lingua,
                        tipo_anomalia, com_proposta)
select DU.id_utilizador, DT.id_tempo, DLO.id_local, DLI.id_lingua,
       get_tipo_anomalia(A.id), anomalia_tem_proposta(A.id)
from anomalia as A,
     incidencia as I,
     (item natural join local_publico) as L,
     d_utilizador as DU,
     d_tempo as DT,
     d_local as DLO,
     d_lingua as DLI
where A.id = I.anomalia_id
      and I.item_id = L.id
      and I.email = DU.email
      and extract (day from A.ts) = DT.dia
      and extract (month from A.ts) = DT.mes
      and extract (year from A.ts) = DT.ano
      and L.latitude = DLO.latitude
      and L.longitude = DLO.longitude
      and A.lingua = DLI.lingua;
    \end{verbatim}


    \Large
    \textbf{Data Analytics}\\
    \normalsize
    \par Para efetuar a análise pedida decidiu-se, por simplicidade, usar a cláusula \textit{CUBE}:
    \footnotesize \begin{verbatim}
    select U.tipo, L.lingua, T.dia_da_semana, count(tipo_anomalia)
    from f_anomalia         natural join
         d_utilizador as U  natural join
         d_tempo as T       natural join
         d_lingua as L
    group by cube(U.tipo, L.lingua, T.dia_da_semana);
    \end{verbatim}\normalsize
\end{document}

